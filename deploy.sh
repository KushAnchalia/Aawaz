#!/bin/bash

echo "ðŸš€ Solana Voice Agent - Deployment Script"

echo " "
echo "Phase 1: Preparing for Ollama Backend + Vercel Frontend Deployment"
echo "==============================================================="

echo " "
echo "1. Ensure you have:"
echo "   - A VPS (DigitalOcean, Linode, AWS) with Ubuntu 22.04"
echo "   - Server IP/domain ready"
echo "   - SSH access configured"

echo " "
echo "2. On your VPS, run these commands:"
echo "------------------------------------"
echo "   # Update system"
echo "   sudo apt update && sudo apt upgrade -y"
echo "   "
echo "   # Install Ollama"
echo "   curl -fsSL https://ollama.ai/install.sh | sh"
echo "   "
echo "   # Start Ollama service"
echo "   sudo systemctl enable ollama"
echo "   sudo systemctl start ollama"
echo "   "
echo "   # Pull the model"
echo "   ollama pull llama3.1"
echo "   "
echo "   # Configure external access"
echo "   sudo nano /etc/systemd/system/ollama.service"
echo "   # Change ExecStart to: /usr/local/bin/ollama serve -H 0.0.0.0:11434"
echo "   "
echo "   # Restart Ollama"
echo "   sudo systemctl daemon-reload"
echo "   sudo systemctl restart ollama"
echo "   "
echo "   # Configure firewall"
echo "   sudo ufw allow 11434"
echo "   sudo ufw enable"

echo " "
echo "3. Update your environment variables:"
echo "-------------------------------------"
echo "   Create .env.local with:"
echo "   LLM_PROVIDER=ollama"
echo "   OLLAMA_URL=https://your-server-domain.com"
echo "   OLLAMA_MODEL=llama3.1"
echo "   HUME_API_KEY=your_key"
echo "   HUME_SECRET_KEY=your_key"

echo " "
echo "4. Deploy to Vercel:"
echo "---------------------"
echo "   # Push to GitHub"
echo "   git add ."
echo "   git commit -m 'Prepare for Ollama deployment'"
echo "   git push origin main"
echo "   "
echo "   # Go to vercel.com and import your repository"
echo "   # Add environment variables in Vercel dashboard"

echo " "
echo "5. Test your deployment:"
echo "------------------------"
echo "   # Test Ollama endpoint"
echo "   curl http://YOUR_SERVER_IP:11434/api/generate -d '{\"model\":\"llama3.1\",\"prompt\":\"Hello\",\"stream\":false}'"
echo "   "
echo "   # Visit your Vercel app URL"

echo " "
echo "âœ… Deployment roadmap complete!"
echo "   Follow the steps above to deploy your Ollama backend and Vercel frontend."